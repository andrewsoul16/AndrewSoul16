{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMD7u8vbPN0iaZ/tgENmgNu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrewsoul16/AndrewSoul16/blob/master/Lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqfvYiBzXJtn",
        "outputId": "20967d8b-12fa-4fbf-9a30-79cbad81b6c6"
      },
      "source": [
        "import numpy, cv2\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "import keras\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras.models import Model, Sequential\r\n",
        "from keras.layers import Dense, Input, Dropout, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers.normalization import BatchNormalization\r\n",
        "from keras.layers.convolutional import Conv2D\r\n",
        "from keras.layers.convolutional import MaxPooling2D\r\n",
        "from keras.layers.core import Activation\r\n",
        "from keras.layers.core import Flatten\r\n",
        "from keras.layers.core import Dropout\r\n",
        "from keras.layers.core import Dense\r\n",
        "from keras import backend as K\r\n",
        "from keras.utils import to_categorical\r\n",
        "\r\n",
        "# Размер входного изображения\r\n",
        "size = 96\r\n",
        "\r\n",
        "# Папка с обучающей выборкой\r\n",
        "train_dir = \"training\"\r\n",
        "\r\n",
        "# Цвет изображения\r\n",
        "CLR = cv2.IMREAD_COLOR #COLOR GRAYSCALE\r\n",
        "\r\n",
        "# Количество классов\r\n",
        "classes = 4\r\n",
        "\r\n",
        "def create_train_data():\r\n",
        "  # Массивы X и Y\r\n",
        "  train_data = []\r\n",
        "  train_labels = []\r\n",
        "  \r\n",
        "  #Индекс класса\r\n",
        "  pp = -1\r\n",
        "  \r\n",
        "  # По всем классам(папкам), и по всем файлам в них\r\n",
        "  for p1 in sorted(os.listdir(train_dir)):\r\n",
        "    if pp == -1: \r\n",
        "      pp=pp+1 \r\n",
        "      continue \r\n",
        "    for img in os.listdir(os.path.join(train_dir, p1)):\r\n",
        "          # Формируем путь к файлу\r\n",
        "          path = os.path.join(os.path.join(train_dir, p1), img)\r\n",
        "          # Изменяем размер изображения и цветовое пространство\r\n",
        "          img = cv2.resize(cv2.imread(path, CLR), (size, size))\r\n",
        "          # Добавляем картинку в обучающую выборку\r\n",
        "          train_data.append(list(np.array(img)))\r\n",
        "          # А также её индекс\r\n",
        "          train_labels.append([pp])\r\n",
        "    print(pp,p1)\r\n",
        "    pp=pp+1\r\n",
        "  \r\n",
        "  # Формируем и выгружаем массивы\r\n",
        "  train_labels = np.array(train_labels)\r\n",
        "  train_data = np.array(train_data)\r\n",
        "  return (train_data,train_labels)\r\n",
        "\r\n",
        "#print(create_train_data())\r\n",
        "\r\n",
        "(X_train, Y_train) = create_train_data()\r\n",
        "Y_train_en = to_categorical(Y_train, num_classes=classes, dtype='float32')\r\n",
        "\r\n",
        "# Конфигурируем модель сети как последовательную\r\n",
        "def build_model():\r\n",
        "    model = Sequential()\r\n",
        "    \r\n",
        "    # размером SIZE*SIZE*3. В первом блоке свёртка окном 3*3 \r\n",
        "    model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=(size, size, 3)))\r\n",
        "    model.add(Activation(\"relu\"))  # Активация ReLU\r\n",
        "    # Подвыборка квадратом 3*3 максимума из квадрата\r\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3)))\r\n",
        "    \r\n",
        "    # [32, size/3, size/3]\r\n",
        "    model.add(Conv2D(32, (3, 3), padding=\"same\"))\r\n",
        "    model.add(Activation(\"relu\"))\r\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "    \r\n",
        "    # [32, size/6, size/6]\r\n",
        "    model.add(Conv2D(64, (3, 3), padding=\"same\"))\r\n",
        "    model.add(Activation(\"relu\"))\r\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "    \r\n",
        "    # [64, size/12, size/12]\r\n",
        "    model.add(Conv2D(128, (3, 3), padding=\"same\"))\r\n",
        "    model.add(Activation(\"relu\"))\r\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "    \r\n",
        "    # [128, size/24, size/24]\r\n",
        "    model.add(Conv2D(64, (3, 3), padding=\"same\"))\r\n",
        "    model.add(Activation(\"relu\"))\r\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "    \r\n",
        "    # [64, size/48, size/48]\r\n",
        "    model.add(Conv2D(32, (3, 3), padding=\"same\"))\r\n",
        "    model.add(Activation(\"relu\"))\r\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "\r\n",
        "    # [32, size/96, size/96]\r\n",
        "    model.add(GlobalAveragePooling2D())\r\n",
        "    model.add(Dense(1024))\r\n",
        "    model.add(Activation(\"relu\"))\r\n",
        " \r\n",
        "    model.add(Dense(classes))\r\n",
        "    model.add(Activation(\"softmax\"))\r\n",
        "    return model\r\n",
        "\r\n",
        "model = build_model()\r\n",
        "model.compile(optimizer=Adam(),\r\n",
        "              loss='categorical_crossentropy',\r\n",
        "              metrics=['categorical_accuracy'])\r\n",
        "\r\n",
        "model.fit(X_train,Y_train_en,epochs=30, batch_size=32)\r\n",
        "\r\n",
        "# Скачиваем скрипт для конвертации сети\r\n",
        "!git clone https://github.com/amir-abdi/keras_to_tensorflow.git\r\n",
        "  \r\n",
        "# Сохраняем сеть в формате Keras\r\n",
        "model.save(\"Keras_model.h5\")\r\n",
        "\r\n",
        "# Сохраняем описание узлов в описании JSON\r\n",
        "model_json = model.to_json()\r\n",
        "with open(\"JSON_model.json\", \"w\") as json_file:\r\n",
        "    json_file.write(model_json)\r\n",
        "\r\n",
        "# Сохраняем описание узлов в \"замороженном\" виде в формате protobuf\r\n",
        "!python keras_to_tensorflow/keras_to_tensorflow.py --input_model=\"Keras_model.h5\" --input_model_json=\"JSON_model.json\" --output_model=\"Final_model.pb\"\r\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Arduino UNO\n",
            "1 FireFly\n",
            "2 Nano Pi\n",
            "3 Raspberry PI\n",
            "Epoch 1/30\n",
            "17/17 [==============================] - 4s 241ms/step - loss: 2.3448 - categorical_accuracy: 0.2775\n",
            "Epoch 2/30\n",
            "17/17 [==============================] - 4s 235ms/step - loss: 1.3444 - categorical_accuracy: 0.3410\n",
            "Epoch 3/30\n",
            "17/17 [==============================] - 4s 237ms/step - loss: 1.2578 - categorical_accuracy: 0.4297\n",
            "Epoch 4/30\n",
            "17/17 [==============================] - 4s 240ms/step - loss: 1.1827 - categorical_accuracy: 0.4605\n",
            "Epoch 5/30\n",
            "17/17 [==============================] - 4s 241ms/step - loss: 0.9487 - categorical_accuracy: 0.6031\n",
            "Epoch 6/30\n",
            "17/17 [==============================] - 4s 246ms/step - loss: 0.6312 - categorical_accuracy: 0.7784\n",
            "Epoch 7/30\n",
            "17/17 [==============================] - 4s 244ms/step - loss: 0.6193 - categorical_accuracy: 0.7611\n",
            "Epoch 8/30\n",
            "17/17 [==============================] - 4s 248ms/step - loss: 0.5189 - categorical_accuracy: 0.8112\n",
            "Epoch 9/30\n",
            "17/17 [==============================] - 4s 251ms/step - loss: 0.3765 - categorical_accuracy: 0.8690\n",
            "Epoch 10/30\n",
            "17/17 [==============================] - 4s 249ms/step - loss: 0.4036 - categorical_accuracy: 0.8651\n",
            "Epoch 11/30\n",
            "17/17 [==============================] - 4s 255ms/step - loss: 0.4373 - categorical_accuracy: 0.8401\n",
            "Epoch 12/30\n",
            "17/17 [==============================] - 4s 236ms/step - loss: 0.2126 - categorical_accuracy: 0.9268\n",
            "Epoch 13/30\n",
            "17/17 [==============================] - 4s 247ms/step - loss: 0.2682 - categorical_accuracy: 0.8979\n",
            "Epoch 14/30\n",
            "17/17 [==============================] - 4s 236ms/step - loss: 0.1077 - categorical_accuracy: 0.9634\n",
            "Epoch 15/30\n",
            "17/17 [==============================] - 4s 251ms/step - loss: 0.0609 - categorical_accuracy: 0.9846\n",
            "Epoch 16/30\n",
            "17/17 [==============================] - 4s 242ms/step - loss: 0.0462 - categorical_accuracy: 0.9846\n",
            "Epoch 17/30\n",
            "17/17 [==============================] - 4s 252ms/step - loss: 0.1750 - categorical_accuracy: 0.9383\n",
            "Epoch 18/30\n",
            "17/17 [==============================] - 4s 239ms/step - loss: 0.0569 - categorical_accuracy: 0.9827\n",
            "Epoch 19/30\n",
            "17/17 [==============================] - 4s 249ms/step - loss: 0.0358 - categorical_accuracy: 0.9865\n",
            "Epoch 20/30\n",
            "17/17 [==============================] - 4s 247ms/step - loss: 0.0797 - categorical_accuracy: 0.9692\n",
            "Epoch 21/30\n",
            "17/17 [==============================] - 4s 241ms/step - loss: 0.0291 - categorical_accuracy: 0.9904\n",
            "Epoch 22/30\n",
            "17/17 [==============================] - 4s 239ms/step - loss: 0.0063 - categorical_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "17/17 [==============================] - 4s 243ms/step - loss: 0.0022 - categorical_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "17/17 [==============================] - 4s 240ms/step - loss: 6.8924e-04 - categorical_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "17/17 [==============================] - 4s 244ms/step - loss: 4.3879e-04 - categorical_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "17/17 [==============================] - 4s 243ms/step - loss: 3.2606e-04 - categorical_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "17/17 [==============================] - 4s 253ms/step - loss: 2.6319e-04 - categorical_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "17/17 [==============================] - 4s 254ms/step - loss: 2.1441e-04 - categorical_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "17/17 [==============================] - 5s 269ms/step - loss: 1.7807e-04 - categorical_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "17/17 [==============================] - 4s 247ms/step - loss: 1.5433e-04 - categorical_accuracy: 1.0000\n",
            "Cloning into 'keras_to_tensorflow'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 166 (delta 3), reused 4 (delta 1), pack-reused 156\u001b[K\n",
            "Receiving objects: 100% (166/166), 150.29 KiB | 6.83 MiB/s, done.\n",
            "Resolving deltas: 100% (80/80), done.\n",
            "2020-12-08 22:07:54.166599: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "WARNING:tensorflow:From keras_to_tensorflow/keras_to_tensorflow.py:23: set_learning_phase (from tensorflow.python.keras.backend) is deprecated and will be removed after 2020-10-11.\n",
            "Instructions for updating:\n",
            "Simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "2020-12-08 22:07:55.805701: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-12-08 22:07:55.814889: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-12-08 22:07:55.814941: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (89576ad62f9e): /proc/driver/nvidia/version does not exist\n",
            "2020-12-08 22:07:55.852995: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz\n",
            "2020-12-08 22:07:55.853243: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x28d8bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-12-08 22:07:55.853281: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "I1208 22:07:55.983196 139800990640000 keras_to_tensorflow.py:146] Converted output node names are: ['activation_15/Softmax']\n",
            "Traceback (most recent call last):\n",
            "  File \"keras_to_tensorflow/keras_to_tensorflow.py\", line 182, in <module>\n",
            "    app.run(main)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 300, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 251, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"keras_to_tensorflow/keras_to_tensorflow.py\", line 148, in main\n",
            "    sess = K.get_session()\n",
            "AttributeError: module 'keras.backend' has no attribute 'get_session'\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}